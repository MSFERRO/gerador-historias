const express = require('express');
const cors = require('cors');
const path = require('path');
const { OpenAI } = require('openai');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3001;

// Middlewares
app.use(cors());
app.use(express.json({ limit: '10mb' }));

// âœ… CONFIGURAÃ‡ÃƒO OPENAI
console.log('\nğŸ”§ CONFIGURANDO OPENAI GPT-4o-mini...');

let openai;
let aiStatus = 'NOT_CONFIGURED';
const ACTIVE_MODEL = 'gpt-4o-mini';

// âœ… VERIFICAÃ‡ÃƒO DA API KEY
if (process.env.OPENAI_API_KEY && process.env.OPENAI_API_KEY.startsWith('sk-')) {
    console.log('âœ… OpenAI API Key detectada:', process.env.OPENAI_API_KEY.substring(0, 12) + '...');
    
    try {
        openai = new OpenAI({ 
            apiKey: process.env.OPENAI_API_KEY,
            timeout: 30000
        });
        aiStatus = 'CONFIGURED';
        console.log('âœ… OpenAI instanciado com sucesso!');
        console.log('ğŸ¤– Modelo:', ACTIVE_MODEL);
        
        // Teste de conexÃ£o
        (async () => {
            try {
                console.log('ğŸ”„ Testando conexÃ£o OpenAI...');
                const test = await openai.chat.completions.create({
                    messages: [{ role: "user", content: "Teste de conexÃ£o" }],
                    model: ACTIVE_MODEL,
                    max_tokens: 5,
                });
                aiStatus = 'WORKING';
                console.log('ğŸ‰ CONEXÃƒO OPENAI: OK -', test.choices[0]?.message?.content);
            } catch (error) {
                aiStatus = 'ERROR';
                console.log('âŒ Erro no teste OpenAI:', error.message);
            }
        })();
        
    } catch (error) {
        console.log('âŒ Erro ao criar OpenAI:', error.message);
    }
} else {
    console.log('âŒ OpenAI API Key nÃ£o encontrada ou invÃ¡lida');
    console.log('ğŸ’¡ Chave no .env:', process.env.OPENAI_API_KEY ? 'EXISTE' : 'NÃƒO EXISTE');
}

console.log('ğŸ“Š Status AI:', aiStatus);

// âœ… FUNÃ‡ÃƒO IA COM OPENAI
async function generateWithAI(projectTitle, clientName, description) {
    console.log(`\nğŸ¤– SOLICITANDO IA... (Status: ${aiStatus})`);
    
    if (!openai || aiStatus !== 'WORKING') {
        console.log('ğŸ”° Usando fallback - OpenAI nÃ£o disponÃ­vel');
        return generateFallbackStory(projectTitle, clientName, description);
    }

    try {
        console.log('ğŸš€ Chamando OpenAI...');
        
        const prompt = `Como Product Owner SÃªnior, gere uma histÃ³ria de usuÃ¡rio completa em portuguÃªs:

PROJETO: ${projectTitle}
CLIENTE: ${clientName}
DESCRIÃ‡ÃƒO: ${description}

Formato profissional com:
- COMO [persona], QUERO [objetivo], PARA [benefÃ­cio]
- CritÃ©rios de aceitaÃ§Ã£o detalhados
- CenÃ¡rios de teste BDD
- Requisitos nÃ£o funcionais

Seja detalhado e use markdown.`;

        const completion = await openai.chat.completions.create({
            messages: [
                {
                    role: "system",
                    content: "VocÃª Ã© um Product Owner experiente. Gere histÃ³rias de usuÃ¡rio profissionais em portuguÃªs."
                },
                {
                    role: "user",
                    content: prompt
                }
            ],
            model: ACTIVE_MODEL,
            temperature: 0.7,
            max_tokens: 2000,
        });

        const aiResponse = completion.choices[0]?.message?.content;
        
        if (aiResponse && aiResponse.length > 100) {
            console.log('âœ… OpenAI respondeu!', aiResponse.length, 'caracteres');
            return `
SISTEMA: ${projectTitle.toUpperCase()}
CLIENTE: ${clientName}
DATA: ${new Date().toLocaleDateString('pt-BR')}
VERSÃƒO: 4.0 - OpenAI GPT-4o-mini

================================================================================
HISTÃ“RIA DE USUÃRIO GERADA POR IA
================================================================================

${aiResponse}

================================================================================

DOCUMENTO GERADO POR OPENAI GPT - SINAPSYS TECNOLOGIA
${new Date().toLocaleString('pt-BR')}
`.trim();
        }
        
        throw new Error('Resposta muito curta');
        
    } catch (error) {
        console.error('âŒ Erro OpenAI:', error.message);
        return generateFallbackStory(projectTitle, clientName, description);
    }
}

// âœ… FALLBACK
function generateFallbackStory(projectTitle, clientName, description) {
    return `
SISTEMA: ${projectTitle.toUpperCase()}
CLIENTE: ${clientName}
DATA: ${new Date().toLocaleDateString('pt-BR')}
VERSÃƒO: 4.0 - Processamento Inteligente

**COMO** Gerente de Projetos
**QUERO** ${description.substring(0, 100)}...
**PARA** melhorar a eficiÃªncia operacional

DOCUMENTO GERADO POR PROCESSAMENTO INTELIGENTE
${new Date().toLocaleString('pt-BR')}
`.trim();
}

// âœ… ROTAS COM INFO DA IA
app.get('/api/health', (req, res) => {
    res.json({ 
        status: 'OK',
        ai: {
            provider: 'OpenAI',
            status: aiStatus,
            ready: aiStatus === 'WORKING',
            configured: !!openai,
            model: ACTIVE_MODEL
        },
        timestamp: new Date().toISOString()
    });
});

app.get('/api/test-ai', async (req, res) => {
    if (!openai) {
        return res.json({
            status: 'ERROR',
            message: 'OpenAI nÃ£o configurado',
            aiStatus: aiStatus
        });
    }

    try {
        const completion = await openai.chat.completions.create({
            messages: [{ role: "user", content: "Responda com: IA FUNCIONANDO" }],
            model: ACTIVE_MODEL,
            max_tokens: 10,
        });

        res.json({
            status: 'SUCCESS',
            message: 'OpenAI estÃ¡ funcionando!',
            response: completion.choices[0]?.message?.content,
            aiStatus: aiStatus
        });

    } catch (error) {
        res.json({
            status: 'ERROR',
            message: 'Erro na OpenAI',
            error: error.message
        });
    }
});

// âœ… ROTA PRINCIPAL
app.post('/api/generate-story', async (req, res) => {
    try {
        const { projectTitle, clientName, description } = req.body;

        console.log(`\nğŸ“¥ REQUISIÃ‡ÃƒO: ${projectTitle}`);
        console.log('   OpenAI Status:', aiStatus);

        const startTime = Date.now();
        const story = await generateWithAI(projectTitle, clientName, description);
        const processingTime = Date.now() - startTime;

        const usingAI = story.includes('OpenAI GPT');
        console.log(`âœ… Gerado em ${processingTime}ms | OpenAI: ${usingAI ? 'SIM' : 'NÃƒO'}`);

        res.json({
            success: true,
            story: story,
            metadata: {
                aiGenerated: usingAI,
                mode: usingAI ? 'OpenAI GPT' : 'Processamento Inteligente',
                processingTime: `${processingTime}ms`,
                aiStatus: aiStatus
            }
        });

    } catch (error) {
        console.error('ğŸ’¥ Erro:', error);
        res.status(500).json({ error: 'Erro interno' });
    }
});

app.get('/', (req, res) => {
    res.json({ 
        message: 'ğŸš€ SINAPSYS OPENAI BACKEND',
        aiStatus: aiStatus,
        model: ACTIVE_MODEL
    });
});

app.listen(PORT, () => {
    console.log('\n========================================');
    console.log('ğŸš€ SINAPSYS OPENAI - ONLINE');
    console.log(`ğŸ“ Porta: ${PORT}`);
    console.log(`ğŸŒ Ambiente: ${process.env.NODE_ENV}`);
    console.log(`ğŸ¤– AI Status: ${aiStatus}`);
    console.log(`ğŸ§  Modelo: ${ACTIVE_MODEL}`);
    console.log('========================================\n');
});